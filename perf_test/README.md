# Performance testing

Чтобы провести нагрузочное тестирование, нужно решить несколько вопросов:

## Выбор основных данных для тестирования

В movie-gate есть фильмы, рецензии, профили, персоны, коллекции - автоген или пользовательские. 
В приложении большая часть использования идет на поток чтения.
Нас же интересует ядро проекта - фильмы и автоген коллекции, например популярное. Фильмы также тянут и персон в API.

## Выборка данных

Для тестирования неважно содержание данных, то есть чтобы они были реальными. Условно есть какое-то описание 
и неважно будет ли там что-то осмысленное или набор символов, главное чтобы порядок длинны сообщения был сопоставим 
с реальными данными.

## Инструментарий

- кастомный генератор данных - нужно сгенерировать 1 000 000 записей по фильмам.
- наполнитель данных - нужно создать инструмент, который будет пакетами заливать все необходимые данные.
- специальный инструмент - для нагрузки HTTP сервера с постоянной частотой запросов и документации.

## До оптимизации

DDL можно наблюдать [тут](ddl/begin).

### Результаты тестирования

## Результаты после оптимизации 

DDL можно наблюдать [тут](ddl/end).

### Результаты тестирования

### Сравнительная характеристика до и после

### Как удалось достичь

## Проблемы 

Первая проблема появилась когда речь пошла о больших данных. PostgreSQL не тянет более 65535 value для вставки.
Помогла множественная адаптивная пакетная вставка. 
Пример [film.go](../internal/pkg/dev/fillerdb/film.go).

Также нужно было оптимизировать запросы. Нельзя было просто так взять и обновить все денормализованные поля 1 запросом.
То есть будет очень неэффективно делать подзапросы с GROUP BY *_id для всех фильмов. 
Запрос серфил по таблицам с 1 000 000 и 5 500 000 записями. Была попытка такого подхода, запрос 
выполнялся 15 ч до того как офнул.

Но даже с этими решениями полный автоген занимал порядка 38 минут (профит с прошлым вариантом по меньшей мере в 22 раза). 
Конфиг [debug.toml](../cmd/filldb/configs/debug.toml).
Решение было простым 1 раз полностью сгенерить базу, сделать физичиский backup и подгружать при необходимости. 
Только нужно контролировать доступ ролей отдельно. [5_user_access.up.sql](../scripts/migrations/up/5_user_access.up.sql).
Физическое копирование не несет в себе данных о ролях, в отличие от логического. По итогу 38 минут -> 47 сек

Дополнительно стоит отметить, что нужно поднимать таймауты для таких больших запросов. На стороне приложения и на стороне БД.

## Примечание

API документация [тут](https://app.swaggerhub.com/apis/BugOverload/API-Kino/1.0.0).

Работа наполнителя:

![image](https://user-images.githubusercontent.com/88785411/212561311-1bdc37d9-8f90-44bc-b029-91b7433f2966.png)

334,52s user 132,25s system 19% cpu 38:56,87 total
